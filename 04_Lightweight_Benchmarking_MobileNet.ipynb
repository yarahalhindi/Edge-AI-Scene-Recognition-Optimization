{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di90yK-vLxeM",
        "outputId": "3dcf8f34-800b-4312-cb75-8be8ccf3d12e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Extracting dataset...\n",
            "Dataset Root Found: /content/dataset/DL_PROJECT_DATASET/Final_Dataset\n",
            "------------------------------\n",
            "Classes: ['building', 'car', 'lab', 'person', 'tree']\n",
            "Split: Train(1654) | Val(354) | Test(355)\n",
            "Batch Shape: torch.Size([32, 3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "SEED = 42\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = 224\n",
        "DATA_PATH = '/content/drive/MyDrive/DL_PROJECT_DATASET.zip'\n",
        "EXTRACT_PATH = '/content/dataset'\n",
        "\n",
        "# 1. SETUP ENV\n",
        "torch.manual_seed(SEED)\n",
        "Image.MAX_IMAGE_PIXELS = None  # Fix Decompression Bomb Error\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# 2. EXTRACT DATA\n",
        "if not os.path.exists(EXTRACT_PATH):\n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(DATA_PATH, 'r') as zip_ref:\n",
        "        zip_ref.extractall(EXTRACT_PATH)\n",
        "else:\n",
        "    print(\"Dataset already extracted.\")\n",
        "\n",
        "# 3. AUTO-DETECT CORRECT ROOT (Fixes Nested Folder Issue)\n",
        "def find_classes_root(start_path):\n",
        "    for root, dirs, files in os.walk(start_path):\n",
        "        if len(dirs) == 5: # We look for exactly 5 classes\n",
        "            return root\n",
        "    raise FileNotFoundError(\"Could not find a directory with exactly 5 class subfolders.\")\n",
        "\n",
        "TRUE_ROOT = find_classes_root(EXTRACT_PATH)\n",
        "print(f\"Dataset Root Found: {TRUE_ROOT}\")\n",
        "\n",
        "# 4. DEFINE TRANSFORMS\n",
        "# Train: Augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Val/Test: Clean (Resize + Normalize only)\n",
        "clean_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 5. CREATE DATASETS & SPLIT\n",
        "# We create two references to the same data so we can apply different transforms\n",
        "full_data_train = datasets.ImageFolder(root=TRUE_ROOT, transform=train_transform)\n",
        "full_data_clean = datasets.ImageFolder(root=TRUE_ROOT, transform=clean_transform)\n",
        "\n",
        "# Calculate Sizes (70/15/15)\n",
        "total_size = len(full_data_train)\n",
        "train_size = int(0.70 * total_size)\n",
        "val_size = int(0.15 * total_size)\n",
        "test_size = total_size - train_size - val_size\n",
        "\n",
        "# Generate Reproducible Indices\n",
        "generator = torch.Generator().manual_seed(SEED)\n",
        "indices = torch.randperm(total_size, generator=generator).tolist()\n",
        "\n",
        "train_idx = indices[:train_size]\n",
        "val_idx = indices[train_size : train_size + val_size]\n",
        "test_idx = indices[train_size + val_size :]\n",
        "\n",
        "# Create Subsets (Train gets augs, Val/Test get clean)\n",
        "train_data = Subset(full_data_train, train_idx)\n",
        "val_data = Subset(full_data_clean, val_idx)\n",
        "test_data = Subset(full_data_clean, test_idx)\n",
        "\n",
        "# 6. DATALOADERS\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# 7. VERIFICATION\n",
        "print(\"-\" * 30)\n",
        "print(f\"Classes: {full_data_train.classes}\")\n",
        "print(f\"Split: Train({len(train_data)}) | Val({len(val_data)}) | Test({len(test_data)})\")\n",
        "print(f\"Batch Shape: {next(iter(train_loader))[0].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Allow loading the huge images one last time to resize them\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "\n",
        "TARGET_SIZE = 500  # Reasonable size (larger than 224, but small enough to load fast)\n",
        "dataset_root = '/content/dataset/DL_PROJECT_DATASET/Final_Dataset'\n",
        "\n",
        "print(f\"Sanitizing dataset at: {dataset_root}\")\n",
        "\n",
        "# Counters\n",
        "resized_count = 0\n",
        "corrupt_count = 0\n",
        "total_count = 0\n",
        "\n",
        "# Walk through all files\n",
        "for root, dirs, files in os.walk(dataset_root):\n",
        "    for file in tqdm(files, desc=\"Processing Images\"):\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "            total_count += 1\n",
        "            file_path = os.path.join(root, file)\n",
        "\n",
        "            try:\n",
        "                # Open image\n",
        "                with Image.open(file_path) as img:\n",
        "                    # Check if it needs resizing (if either side is huge)\n",
        "                    if img.width > TARGET_SIZE or img.height > TARGET_SIZE:\n",
        "                        # Convert to RGB (fixes PNG transparency issues if any)\n",
        "                        img = img.convert('RGB')\n",
        "\n",
        "                        # Resize maintaining aspect ratio\n",
        "                        img.thumbnail((TARGET_SIZE, TARGET_SIZE))\n",
        "\n",
        "                        # Save back to same path\n",
        "                        img.save(file_path)\n",
        "                        resized_count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Corrupt image found and removed: {file_path}\")\n",
        "                os.remove(file_path)\n",
        "                corrupt_count += 1\n",
        "\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(f\"Total Images Scanned: {total_count}\")\n",
        "print(f\"Resized Huge Images: {resized_count}\")\n",
        "print(f\"Deleted Corrupt Images: {corrupt_count}\")\n",
        "print(\"=\"*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI_llN5mOgoJ",
        "outputId": "e45750bd-39f0-4f7e-a3f8-87220a165c8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanitizing dataset at: /content/dataset/DL_PROJECT_DATASET/Final_Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Images: 0it [00:00, ?it/s]\n",
            "Processing Images: 100%|██████████| 573/573 [00:43<00:00, 13.17it/s]\n",
            "Processing Images: 100%|██████████| 447/447 [01:35<00:00,  4.66it/s]\n",
            "Processing Images: 100%|██████████| 419/419 [00:55<00:00,  7.54it/s]\n",
            "Processing Images: 100%|██████████| 368/368 [00:28<00:00, 12.77it/s]\n",
            "Processing Images: 100%|██████████| 556/556 [00:45<00:00, 12.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "Total Images Scanned: 2363\n",
            "Resized Huge Images: 2362\n",
            "Deleted Corrupt Images: 0\n",
            "==============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 10\n",
        "SAVE_PATH = '/content/drive/MyDrive/baseline_mobilenet_v2.pth'\n",
        "\n",
        "# 1. BUILD MODEL\n",
        "print(f\"Building MobileNetV2 for {len(full_data_train.classes)} classes...\")\n",
        "model = mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)\n",
        "\n",
        "# Freeze Feature Extractor (Transfer Learning Standard)\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace Classifier (The only part we train)\n",
        "# MobileNet's classifier is a Sequential block; index 1 is the Linear layer\n",
        "in_features = model.classifier[1].in_features\n",
        "model.classifier[1] = nn.Linear(in_features, len(full_data_train.classes))\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "# 2. OPTIMIZER & LOSS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# 3. TRAINING FUNCTION\n",
        "def train_model(model, train_loader, val_loader, epochs):\n",
        "    best_acc = 0.0\n",
        "    best_weights = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    print(f\"Training on {DEVICE}...\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        # --- TRAIN ---\n",
        "        model.train()\n",
        "        train_loss, train_correct, train_total = 0, 0, 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            train_correct += (preds == labels).sum().item()\n",
        "            train_total += labels.size(0)\n",
        "\n",
        "        train_acc = train_correct / train_total\n",
        "        avg_train_loss = train_loss / train_total\n",
        "\n",
        "        # --- VALIDATE ---\n",
        "        model.eval()\n",
        "        val_correct, val_total = 0, 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_correct += (preds == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        # --- SAVE BEST ---\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_weights = copy.deepcopy(model.state_dict())\n",
        "            torch.save(model.state_dict(), SAVE_PATH) # Save to Drive\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "              f\"Train Acc: {train_acc:.4f} | \"\n",
        "              f\"Val Acc: {val_acc:.4f} | \"\n",
        "              f\"Time: {time.time() - start:.1f}s\")\n",
        "\n",
        "    print(f\"\\nBest Val Acc: {best_acc:.4f}\")\n",
        "    print(f\"Saved to: {SAVE_PATH}\")\n",
        "\n",
        "    model.load_state_dict(best_weights)\n",
        "    return model\n",
        "\n",
        "# 4. RUN\n",
        "baseline_model = train_model(model, train_loader, val_loader, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dMxTerfL2vk",
        "outputId": "b31b05c7-c76d-4c88-8abb-e0d1fe76afb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building MobileNetV2 for 5 classes...\n",
            "Training on cuda...\n",
            "Epoch 1/10 | Train Acc: 0.7944 | Val Acc: 0.8842 | Time: 11.5s\n",
            "Epoch 2/10 | Train Acc: 0.9160 | Val Acc: 0.9011 | Time: 11.5s\n",
            "Epoch 3/10 | Train Acc: 0.9160 | Val Acc: 0.9096 | Time: 11.4s\n",
            "Epoch 4/10 | Train Acc: 0.9274 | Val Acc: 0.9096 | Time: 10.7s\n",
            "Epoch 5/10 | Train Acc: 0.9359 | Val Acc: 0.9181 | Time: 11.3s\n",
            "Epoch 6/10 | Train Acc: 0.9389 | Val Acc: 0.9153 | Time: 11.3s\n",
            "Epoch 7/10 | Train Acc: 0.9541 | Val Acc: 0.9294 | Time: 11.5s\n",
            "Epoch 8/10 | Train Acc: 0.9377 | Val Acc: 0.9266 | Time: 11.3s\n",
            "Epoch 9/10 | Train Acc: 0.9438 | Val Acc: 0.9237 | Time: 11.3s\n",
            "Epoch 10/10 | Train Acc: 0.9480 | Val Acc: 0.9266 | Time: 10.8s\n",
            "\n",
            "Best Val Acc: 0.9294\n",
            "Saved to: /content/drive/MyDrive/baseline_mobilenet_v2.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_baseline(model, loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Load Best Saved Weights\n",
        "    model.load_state_dict(torch.load(SAVE_PATH))\n",
        "    print(f\"Loaded weights from {SAVE_PATH}\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs = inputs.to(DEVICE)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    # Metrics\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"BASELINE MOBILENET V2 - TEST RESULTS\")\n",
        "    print(\"=\"*40)\n",
        "    print(classification_report(all_labels, all_preds,\n",
        "                                target_names=full_data_train.classes,\n",
        "                                digits=4))\n",
        "\n",
        "    # Calculate Overall Accuracy\n",
        "    correct = sum([p == l for p, l in zip(all_preds, all_labels)])\n",
        "    acc = correct / len(all_labels)\n",
        "    print(f\"Final Test Accuracy: {acc*100:.2f}%\")\n",
        "    return acc\n",
        "\n",
        "baseline_acc = evaluate_baseline(baseline_model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6onzK8YNHRD",
        "outputId": "98fc9725-2c9a-43e3-fea4-8b6cc79363c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded weights from /content/drive/MyDrive/baseline_mobilenet_v2.pth\n",
            "\n",
            "========================================\n",
            "BASELINE MOBILENET V2 - TEST RESULTS\n",
            "========================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    building     0.9130    0.9130    0.9130        46\n",
            "         car     0.9605    0.9359    0.9481        78\n",
            "         lab     0.8451    1.0000    0.9160        60\n",
            "      person     1.0000    0.8472    0.9173        72\n",
            "        tree     0.9406    0.9596    0.9500        99\n",
            "\n",
            "    accuracy                         0.9324       355\n",
            "   macro avg     0.9318    0.9312    0.9289       355\n",
            "weighted avg     0.9373    0.9324    0.9324       355\n",
            "\n",
            "Final Test Accuracy: 93.24%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
        "import copy\n",
        "import time\n",
        "\n",
        "# --- 1. DEFINE CBAM BLOCKS ---\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
        "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
        "        out = avg_out + max_out\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        x = torch.cat([avg_out, max_out], dim=1)\n",
        "        x = self.conv1(x)\n",
        "        return self.sigmoid(x)\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, planes):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.ca = ChannelAttention(planes)\n",
        "        self.sa = SpatialAttention()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x * self.ca(x)\n",
        "        x = x * self.sa(x)\n",
        "        return x\n",
        "\n",
        "# --- 2. ASSEMBLE MODEL ---\n",
        "class MobileNetV2_CBAM(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(MobileNetV2_CBAM, self).__init__()\n",
        "        # Load Baseline\n",
        "        base = mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)\n",
        "        self.features = base.features\n",
        "\n",
        "        # Freeze Features (Keep the knowledge)\n",
        "        for param in self.features.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Add CBAM (1280 is the output channel size of MobileNetV2)\n",
        "        self.cbam = CBAM(1280)\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1280, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.cbam(x)          # <--- The Novelty\n",
        "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# --- 3. INIT & TRAIN ---\n",
        "print(\"Building MobileNetV2 + CBAM...\")\n",
        "cbam_model = MobileNetV2_CBAM(num_classes=len(full_data_train.classes)).to(DEVICE)\n",
        "\n",
        "# Note: We must train the CBAM layers AND the classifier\n",
        "# Parameters to update = CBAM + Classifier\n",
        "params_to_update = list(cbam_model.cbam.parameters()) + list(cbam_model.classifier.parameters())\n",
        "\n",
        "optimizer = torch.optim.Adam(params_to_update, lr=0.001)\n",
        "# Reuse the same criterion from before\n",
        "SAVE_PATH_CBAM = '/content/drive/MyDrive/mobilenet_v2_cbam.pth'\n",
        "\n",
        "# Reuse the training function (It's generic!)\n",
        "# We modify the save path logic inside the function or just copy-paste for safety\n",
        "# Let's run a quick custom loop to be safe with the new save path\n",
        "def train_cbam(model, epochs):\n",
        "    best_acc = 0.0\n",
        "    print(f\"Training CBAM Model on {DEVICE}...\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_correct, train_total = 0, 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            train_correct += (preds == labels).sum().item()\n",
        "            train_total += labels.size(0)\n",
        "\n",
        "        # Val\n",
        "        model.eval()\n",
        "        val_correct, val_total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_correct += (preds == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "\n",
        "        val_acc = val_correct / val_total\n",
        "        print(f\"Epoch {epoch+1} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), SAVE_PATH_CBAM)\n",
        "\n",
        "    print(f\"Best CBAM Val Acc: {best_acc:.4f}\")\n",
        "\n",
        "# RUN\n",
        "train_cbam(cbam_model, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJ6CdRdIRP4H",
        "outputId": "739df6a8-674d-4ea5-b397-73200bb1d134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building MobileNetV2 + CBAM...\n",
            "Training CBAM Model on cuda...\n",
            "Epoch 1 | Val Acc: 0.9011\n",
            "Epoch 2 | Val Acc: 0.9096\n",
            "Epoch 3 | Val Acc: 0.9011\n",
            "Epoch 4 | Val Acc: 0.9237\n",
            "Epoch 5 | Val Acc: 0.9237\n",
            "Epoch 6 | Val Acc: 0.9379\n",
            "Epoch 7 | Val Acc: 0.9350\n",
            "Epoch 8 | Val Acc: 0.9350\n",
            "Epoch 9 | Val Acc: 0.9350\n",
            "Epoch 10 | Val Acc: 0.9294\n",
            "Best CBAM Val Acc: 0.9379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reuse the evaluation logic but for the CBAM model\n",
        "def evaluate_cbam(model, loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Load Best Saved Weights\n",
        "    model.load_state_dict(torch.load(SAVE_PATH_CBAM))\n",
        "    print(f\"Loaded weights from {SAVE_PATH_CBAM}\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs = inputs.to(DEVICE)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    # Metrics\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"NOVELTY A (CBAM) - TEST RESULTS\")\n",
        "    print(\"=\"*40)\n",
        "    print(classification_report(all_labels, all_preds,\n",
        "                                target_names=full_data_train.classes,\n",
        "                                digits=4))\n",
        "\n",
        "    correct = sum([p == l for p, l in zip(all_preds, all_labels)])\n",
        "    acc = correct / len(all_labels)\n",
        "    print(f\"Final CBAM Test Accuracy: {acc*100:.2f}%\")\n",
        "    return acc\n",
        "\n",
        "cbam_test_acc = evaluate_cbam(cbam_model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0xKoUPcSIRe",
        "outputId": "798f6d9e-36e0-40a8-aa92-9bb46cb2f878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded weights from /content/drive/MyDrive/mobilenet_v2_cbam.pth\n",
            "\n",
            "========================================\n",
            "NOVELTY A (CBAM) - TEST RESULTS\n",
            "========================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    building     0.8958    0.9348    0.9149        46\n",
            "         car     0.9605    0.9359    0.9481        78\n",
            "         lab     0.8955    1.0000    0.9449        60\n",
            "      person     0.9844    0.8750    0.9265        72\n",
            "        tree     0.9600    0.9697    0.9648        99\n",
            "\n",
            "    accuracy                         0.9437       355\n",
            "   macro avg     0.9393    0.9431    0.9398       355\n",
            "weighted avg     0.9458    0.9437    0.9435       355\n",
            "\n",
            "Final CBAM Test Accuracy: 94.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
        "\n",
        "# --- 1. DEFINE COORDINATE ATTENTION ---\n",
        "class CoordAtt(nn.Module):\n",
        "    def __init__(self, inp, oup, reduction=32):\n",
        "        super(CoordAtt, self).__init__()\n",
        "        # X and Y pooling\n",
        "        self.pool_h = nn.AdaptiveAvgPool2d((None, 1))\n",
        "        self.pool_w = nn.AdaptiveAvgPool2d((1, None))\n",
        "\n",
        "        mip = max(8, inp // reduction)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(inp, mip, kernel_size=1, stride=1, padding=0)\n",
        "        self.bn1 = nn.BatchNorm2d(mip)\n",
        "        self.act = nn.Hardswish() # Modern activation, faster on mobile\n",
        "\n",
        "        self.conv_h = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)\n",
        "        self.conv_w = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        n, c, h, w = x.size()\n",
        "\n",
        "        # 1. Coordinate Pooling\n",
        "        x_h = self.pool_h(x)\n",
        "        x_w = self.pool_w(x).permute(0, 1, 3, 2) # Permute to allow concatenation\n",
        "\n",
        "        # 2. Concatenate & Encode\n",
        "        y = torch.cat([x_h, x_w], dim=2)\n",
        "        y = self.conv1(y)\n",
        "        y = self.bn1(y)\n",
        "        y = self.act(y)\n",
        "\n",
        "        # 3. Split back\n",
        "        x_h, x_w = torch.split(y, [h, w], dim=2)\n",
        "        x_w = x_w.permute(0, 1, 3, 2)\n",
        "\n",
        "        # 4. Generate Weights\n",
        "        a_h = self.conv_h(x_h).sigmoid()\n",
        "        a_w = self.conv_w(x_w).sigmoid()\n",
        "\n",
        "        # 5. Apply\n",
        "        out = identity * a_w * a_h\n",
        "        return out\n",
        "\n",
        "# --- 2. ASSEMBLE MODEL (CA) ---\n",
        "class MobileNetV2_CA(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(MobileNetV2_CA, self).__init__()\n",
        "        base = mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)\n",
        "        self.features = base.features\n",
        "\n",
        "        # Freeze Base\n",
        "        for param in self.features.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Add Coordinate Attention (Input 1280)\n",
        "        self.ca = CoordAtt(1280, 1280)\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1280, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.ca(x)          # <--- The Novelty B\n",
        "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# --- 3. INIT & TRAIN ---\n",
        "print(\"Building MobileNetV2 + Coordinate Attention...\")\n",
        "ca_model = MobileNetV2_CA(num_classes=len(full_data_train.classes)).to(DEVICE)\n",
        "\n",
        "# Update params list\n",
        "params_to_update = list(ca_model.ca.parameters()) + list(ca_model.classifier.parameters())\n",
        "optimizer = torch.optim.Adam(params_to_update, lr=0.001)\n",
        "\n",
        "SAVE_PATH_CA = '/content/drive/MyDrive/mobilenet_v2_ca.pth'\n",
        "\n",
        "# Custom Train Loop for CA\n",
        "def train_ca(model, epochs):\n",
        "    best_acc = 0.0\n",
        "    print(f\"Training CA Model on {DEVICE}...\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        # Train Loop (Condensed)\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Val Loop\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        val_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), SAVE_PATH_CA)\n",
        "\n",
        "    print(f\"Best CA Val Acc: {best_acc:.4f}\")\n",
        "\n",
        "# RUN\n",
        "train_ca(ca_model, epochs=10)"
      ],
      "metadata": {
        "id": "cbLLfNrBTot9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd1f084e-287d-4ee5-88cd-320a6fe30623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building MobileNetV2 + Coordinate Attention...\n",
            "Training CA Model on cuda...\n",
            "Epoch 1 | Val Acc: 0.9040\n",
            "Epoch 2 | Val Acc: 0.9209\n",
            "Epoch 3 | Val Acc: 0.9209\n",
            "Epoch 4 | Val Acc: 0.9322\n",
            "Epoch 5 | Val Acc: 0.9407\n",
            "Epoch 6 | Val Acc: 0.9350\n",
            "Epoch 7 | Val Acc: 0.9350\n",
            "Epoch 8 | Val Acc: 0.9407\n",
            "Epoch 9 | Val Acc: 0.9322\n",
            "Epoch 10 | Val Acc: 0.9435\n",
            "Best CA Val Acc: 0.9435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate_ca_fixed(model, loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    # 1. Robustly get class names from the loader\n",
        "    # (Works whether it's a Subset or a full Dataset)\n",
        "    if hasattr(loader.dataset, 'classes'):\n",
        "        class_names = loader.dataset.classes\n",
        "    elif hasattr(loader.dataset, 'dataset') and hasattr(loader.dataset.dataset, 'classes'):\n",
        "        class_names = loader.dataset.dataset.classes\n",
        "    else:\n",
        "        # Fallback if all else fails\n",
        "        class_names = ['building', 'car', 'lab', 'person', 'tree']\n",
        "\n",
        "    print(f\"Evaluated on classes: {class_names}\")\n",
        "\n",
        "    # Load Weights\n",
        "    model.load_state_dict(torch.load(SAVE_PATH_CA))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs = inputs.to(DEVICE)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    # Metrics\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"NOVELTY B (COORD ATTENTION) - TEST RESULTS\")\n",
        "    print(\"=\"*40)\n",
        "    print(classification_report(all_labels, all_preds,\n",
        "                                target_names=class_names,\n",
        "                                digits=4))\n",
        "\n",
        "    correct = sum([p == l for p, l in zip(all_preds, all_labels)])\n",
        "    acc = correct / len(all_labels)\n",
        "    print(f\"Final CA Test Accuracy: {acc*100:.2f}%\")\n",
        "    return acc\n",
        "\n",
        "ca_test_acc = evaluate_ca_fixed(ca_model, test_loader)"
      ],
      "metadata": {
        "id": "p6km81HGT-gl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4462197f-5e44-4bd8-82e2-44fa8e8cdc99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated on classes: ['building', 'car', 'lab', 'person', 'tree']\n",
            "\n",
            "========================================\n",
            "NOVELTY B (COORD ATTENTION) - TEST RESULTS\n",
            "========================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    building     0.8958    0.9348    0.9149        46\n",
            "         car     0.9868    0.9615    0.9740        78\n",
            "         lab     0.9677    1.0000    0.9836        60\n",
            "      person     0.9861    0.9861    0.9861        72\n",
            "        tree     0.9794    0.9596    0.9694        99\n",
            "\n",
            "    accuracy                         0.9690       355\n",
            "   macro avg     0.9632    0.9684    0.9656       355\n",
            "weighted avg     0.9696    0.9690    0.9691       355\n",
            "\n",
            "Final CA Test Accuracy: 96.90%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import mobilenet_v3_large, MobileNet_V3_Large_Weights\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 10\n",
        "SAVE_PATH_V3 = '/content/drive/MyDrive/mobilenet_v3_ref.pth'\n",
        "NUM_CLASSES = 5  # Hardcoded for stability\n",
        "\n",
        "# --- 2. BUILD MODEL ---\n",
        "print(\"Building MobileNetV3 (Large) Reference...\")\n",
        "v3_model = mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.DEFAULT)\n",
        "\n",
        "# Freeze Features\n",
        "for param in v3_model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify Classifier\n",
        "in_features = v3_model.classifier[-1].in_features\n",
        "v3_model.classifier[-1] = nn.Linear(in_features, NUM_CLASSES)\n",
        "\n",
        "v3_model = v3_model.to(DEVICE)\n",
        "\n",
        "# --- 3. TRAIN ---\n",
        "optimizer = torch.optim.Adam(v3_model.classifier.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_and_evaluate_v3():\n",
        "    best_acc = 0.0\n",
        "    print(f\"Training MobileNetV3 on {DEVICE}...\")\n",
        "\n",
        "    # TRAIN LOOP\n",
        "    for epoch in range(EPOCHS):\n",
        "        v3_model.train()\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = v3_model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # VAL LOOP\n",
        "        v3_model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "                outputs = v3_model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        val_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(v3_model.state_dict(), SAVE_PATH_V3)\n",
        "\n",
        "    print(f\"Best V3 Val Acc: {best_acc:.4f}\")\n",
        "\n",
        "    # TEST LOOP (Immediate)\n",
        "    print(\"\\nEvaluating V3 on Test Set...\")\n",
        "    v3_model.load_state_dict(torch.load(SAVE_PATH_V3)) # Load best\n",
        "    v3_model.eval()\n",
        "\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = v3_model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    final_acc = correct / total\n",
        "    print(f\"Final MobileNetV3 Test Accuracy: {final_acc*100:.2f}%\")\n",
        "    return final_acc\n",
        "\n",
        "# RUN\n",
        "v3_test_acc = train_and_evaluate_v3()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd8TnmHyWQCK",
        "outputId": "47f41421-de12-408c-e2dd-b57df241a719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building MobileNetV3 (Large) Reference...\n",
            "Training MobileNetV3 on cuda...\n",
            "Epoch 1 | Val Acc: 0.8672\n",
            "Epoch 2 | Val Acc: 0.9266\n",
            "Epoch 3 | Val Acc: 0.9322\n",
            "Epoch 4 | Val Acc: 0.9463\n",
            "Epoch 5 | Val Acc: 0.9350\n",
            "Epoch 6 | Val Acc: 0.9463\n",
            "Epoch 7 | Val Acc: 0.9350\n",
            "Epoch 8 | Val Acc: 0.9350\n",
            "Epoch 9 | Val Acc: 0.9350\n",
            "Epoch 10 | Val Acc: 0.9266\n",
            "Best V3 Val Acc: 0.9463\n",
            "\n",
            "Evaluating V3 on Test Set...\n",
            "Final MobileNetV3 Test Accuracy: 96.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision.models import mobilenet_v2, mobilenet_v3_large\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "NUM_CLASSES = 5\n",
        "DUMMY_INPUT = torch.randn(1, 3, 224, 224).to(DEVICE) # Simulates 1 image\n",
        "PATHS = {\n",
        "    'Baseline (V2)': '/content/drive/MyDrive/baseline_mobilenet_v2.pth',\n",
        "    'Novelty A (CBAM)': '/content/drive/MyDrive/mobilenet_v2_cbam.pth',\n",
        "    'Novelty B (CA)': '/content/drive/MyDrive/mobilenet_v2_ca.pth',\n",
        "    'Reference (V3)': '/content/drive/MyDrive/mobilenet_v3_ref.pth'\n",
        "}\n",
        "\n",
        "# --- RE-DEFINE ARCHITECTURES (Required for loading) ---\n",
        "# 1. CBAM Components\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.fc2(self.relu1(self.fc1(self.avg_pool(x)))) +\n",
        "                            self.fc2(self.relu1(self.fc1(self.max_pool(x)))))\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.conv1(torch.cat([torch.mean(x, dim=1, keepdim=True),\n",
        "                                                  torch.max(x, dim=1, keepdim=True)[0]], dim=1)))\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, planes):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.ca = ChannelAttention(planes)\n",
        "        self.sa = SpatialAttention()\n",
        "    def forward(self, x):\n",
        "        return x * self.ca(x) * self.sa(x)\n",
        "\n",
        "class MobileNetV2_CBAM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MobileNetV2_CBAM, self).__init__()\n",
        "        base = mobilenet_v2()\n",
        "        self.features = base.features\n",
        "        self.cbam = CBAM(1280)\n",
        "        self.classifier = nn.Sequential(nn.Dropout(0.2), nn.Linear(1280, NUM_CLASSES))\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.cbam(x)\n",
        "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n",
        "        x = self.classifier(torch.flatten(x, 1))\n",
        "        return x\n",
        "\n",
        "# 2. CoordAtt Components\n",
        "class CoordAtt(nn.Module):\n",
        "    def __init__(self, inp, oup, reduction=32):\n",
        "        super(CoordAtt, self).__init__()\n",
        "        self.pool_h = nn.AdaptiveAvgPool2d((None, 1))\n",
        "        self.pool_w = nn.AdaptiveAvgPool2d((1, None))\n",
        "        mip = max(8, inp // reduction)\n",
        "        self.conv1 = nn.Conv2d(inp, mip, kernel_size=1, stride=1, padding=0)\n",
        "        self.bn1 = nn.BatchNorm2d(mip)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.conv_h = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)\n",
        "        self.conv_w = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        n, c, h, w = x.size()\n",
        "        x_h = self.pool_h(x)\n",
        "        x_w = self.pool_w(x).permute(0, 1, 3, 2)\n",
        "        y = torch.cat([x_h, x_w], dim=2)\n",
        "        y = self.act(self.bn1(self.conv1(y)))\n",
        "        x_h, x_w = torch.split(y, [h, w], dim=2)\n",
        "        x_w = x_w.permute(0, 1, 3, 2)\n",
        "        return identity * self.conv_h(x_h).sigmoid() * self.conv_w(x_w).sigmoid()\n",
        "\n",
        "class MobileNetV2_CA(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MobileNetV2_CA, self).__init__()\n",
        "        base = mobilenet_v2()\n",
        "        self.features = base.features\n",
        "        self.ca = CoordAtt(1280, 1280)\n",
        "        self.classifier = nn.Sequential(nn.Dropout(0.2), nn.Linear(1280, NUM_CLASSES))\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.ca(x)\n",
        "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n",
        "        x = self.classifier(torch.flatten(x, 1))\n",
        "        return x\n",
        "\n",
        "# --- HELPER TO BUILD AND LOAD ---\n",
        "def load_model(name):\n",
        "    if 'Baseline' in name:\n",
        "        m = mobilenet_v2()\n",
        "        m.classifier[1] = nn.Linear(m.classifier[1].in_features, NUM_CLASSES)\n",
        "    elif 'CBAM' in name:\n",
        "        m = MobileNetV2_CBAM()\n",
        "    elif 'CA' in name:\n",
        "        m = MobileNetV2_CA()\n",
        "    elif 'V3' in name:\n",
        "        m = mobilenet_v3_large()\n",
        "        m.classifier[-1] = nn.Linear(m.classifier[-1].in_features, NUM_CLASSES)\n",
        "\n",
        "    # Load weights safely\n",
        "    try:\n",
        "        m.load_state_dict(torch.load(PATHS[name], map_location=DEVICE))\n",
        "        m.to(DEVICE)\n",
        "        m.eval()\n",
        "        return m\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Warning: Could not find weights for {name}\")\n",
        "        return None\n",
        "\n",
        "# --- SPEED TEST ---\n",
        "print(f\"{'Model Name':<20} | {'Parameters':<10} | {'Inference (ms)':<15} | {'FPS':<10}\")\n",
        "print(\"-\" * 65)\n",
        "\n",
        "for name in PATHS.keys():\n",
        "    model = load_model(name)\n",
        "    if model is None: continue\n",
        "\n",
        "    # 1. Count Params\n",
        "    params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "    # 2. Warmup (GPU needs this)\n",
        "    for _ in range(20):\n",
        "        _ = model(DUMMY_INPUT)\n",
        "\n",
        "    # 3. Timed Run\n",
        "    start = time.time()\n",
        "    for _ in range(100): # Run 100 times\n",
        "        with torch.no_grad():\n",
        "            _ = model(DUMMY_INPUT)\n",
        "    end = time.time()\n",
        "\n",
        "    total_time = end - start\n",
        "    avg_time_ms = (total_time / 100) * 1000\n",
        "    fps = 100 / total_time\n",
        "\n",
        "    print(f\"{name:<20} | {params/1e6:.2f}M       | {avg_time_ms:.2f} ms        | {fps:.0f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMu2KIfMWwBC",
        "outputId": "4293a424-cace-4af6-cba2-cb996a6ebacb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Name           | Parameters | Inference (ms)  | FPS       \n",
            "-----------------------------------------------------------------\n",
            "Baseline (V2)        | 2.23M       | 11.43 ms        | 87\n",
            "Novelty A (CBAM)     | 2.44M       | 5.94 ms        | 168\n",
            "Novelty B (CA)       | 2.39M       | 7.08 ms        | 141\n",
            "Reference (V3)       | 4.21M       | 8.48 ms        | 118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import numpy as np\n",
        "from torchvision.models import mobilenet_v2, mobilenet_v3_large\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "NUM_CLASSES = 5\n",
        "PATHS = {\n",
        "    'Baseline (V2)': '/content/drive/MyDrive/baseline_mobilenet_v2.pth',\n",
        "    'Novelty A (CBAM)': '/content/drive/MyDrive/mobilenet_v2_cbam.pth',\n",
        "    'Novelty B (CA)': '/content/drive/MyDrive/mobilenet_v2_ca.pth',\n",
        "    'Reference (V3)': '/content/drive/MyDrive/mobilenet_v3_ref.pth'\n",
        "}\n",
        "\n",
        "# --- ARCHITECTURE DEFINITIONS (Needed to load weights) ---\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, planes):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.ca = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Conv2d(planes, planes//16, 1), nn.ReLU(), nn.Conv2d(planes//16, planes, 1), nn.Sigmoid())\n",
        "        self.sa = nn.Sequential(nn.Conv2d(2, 1, 7, padding=3), nn.Sigmoid())\n",
        "    def forward(self, x):\n",
        "        # Simplified Forward for brevity\n",
        "        ca_out = self.ca(x) * x # Note: Simplified implementation logic for loading\n",
        "        # Re-using the exact classes from previous steps is safer, but let's stick to structure\n",
        "        # actually, to avoid key mismatch, we must use EXACT definitions used in training.\n",
        "        # I will rely on the fact that we define the classes below exactly as before.\n",
        "        return x\n",
        "\n",
        "# REDEFINE EXACT CLASSES USED IN TRAINING\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.fc2(self.relu1(self.fc1(self.avg_pool(x)))) + self.fc2(self.relu1(self.fc1(self.max_pool(x)))))\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.conv1(torch.cat([torch.mean(x, dim=1, keepdim=True), torch.max(x, dim=1, keepdim=True)[0]], dim=1)))\n",
        "\n",
        "class CBAM_Block(nn.Module):\n",
        "    def __init__(self, planes):\n",
        "        super(CBAM_Block, self).__init__()\n",
        "        self.ca = ChannelAttention(planes)\n",
        "        self.sa = SpatialAttention()\n",
        "    def forward(self, x):\n",
        "        return x * self.ca(x) * self.sa(x)\n",
        "\n",
        "class MobileNetV2_CBAM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MobileNetV2_CBAM, self).__init__()\n",
        "        base = mobilenet_v2()\n",
        "        self.features = base.features\n",
        "        self.cbam = CBAM_Block(1280)\n",
        "        self.classifier = nn.Sequential(nn.Dropout(0.2), nn.Linear(1280, NUM_CLASSES))\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.cbam(x)\n",
        "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n",
        "        x = self.classifier(torch.flatten(x, 1))\n",
        "        return x\n",
        "\n",
        "class CoordAtt(nn.Module):\n",
        "    def __init__(self, inp, oup, reduction=32):\n",
        "        super(CoordAtt, self).__init__()\n",
        "        self.pool_h = nn.AdaptiveAvgPool2d((None, 1))\n",
        "        self.pool_w = nn.AdaptiveAvgPool2d((1, None))\n",
        "        mip = max(8, inp // reduction)\n",
        "        self.conv1 = nn.Conv2d(inp, mip, kernel_size=1, stride=1, padding=0)\n",
        "        self.bn1 = nn.BatchNorm2d(mip)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.conv_h = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)\n",
        "        self.conv_w = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        n, c, h, w = x.size()\n",
        "        x_h = self.pool_h(x)\n",
        "        x_w = self.pool_w(x).permute(0, 1, 3, 2)\n",
        "        y = torch.cat([x_h, x_w], dim=2)\n",
        "        y = self.act(self.bn1(self.conv1(y)))\n",
        "        x_h, x_w = torch.split(y, [h, w], dim=2)\n",
        "        x_w = x_w.permute(0, 1, 3, 2)\n",
        "        return identity * self.conv_h(x_h).sigmoid() * self.conv_w(x_w).sigmoid()\n",
        "\n",
        "class MobileNetV2_CA(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MobileNetV2_CA, self).__init__()\n",
        "        base = mobilenet_v2()\n",
        "        self.features = base.features\n",
        "        self.ca = CoordAtt(1280, 1280)\n",
        "        self.classifier = nn.Sequential(nn.Dropout(0.2), nn.Linear(1280, NUM_CLASSES))\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.ca(x)\n",
        "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n",
        "        x = self.classifier(torch.flatten(x, 1))\n",
        "        return x\n",
        "\n",
        "# --- METRIC GATHERING ---\n",
        "def get_metrics(name, path, loader):\n",
        "    # 1. Load Model\n",
        "    if 'Baseline' in name:\n",
        "        model = mobilenet_v2()\n",
        "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, NUM_CLASSES)\n",
        "    elif 'CBAM' in name:\n",
        "        model = MobileNetV2_CBAM()\n",
        "    elif 'CA' in name:\n",
        "        model = MobileNetV2_CA()\n",
        "    elif 'V3' in name:\n",
        "        model = mobilenet_v3_large()\n",
        "        model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, NUM_CLASSES)\n",
        "\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(path, map_location=DEVICE))\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "\n",
        "    # 2. Parameters\n",
        "    params = sum(p.numel() for p in model.parameters()) / 1e6\n",
        "\n",
        "    # 3. Accuracy\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    acc = 100 * correct / total\n",
        "\n",
        "    # 4. Inference Speed\n",
        "    dummy = torch.randn(1, 3, 224, 224).to(DEVICE)\n",
        "    # Warmup\n",
        "    for _ in range(50): _ = model(dummy)\n",
        "\n",
        "    # Timing\n",
        "    start = time.time()\n",
        "    for _ in range(200): # 200 runs for stability\n",
        "        with torch.no_grad(): _ = model(dummy)\n",
        "    end = time.time()\n",
        "\n",
        "    avg_ms = ((end - start) / 200) * 1000\n",
        "    fps = 200 / (end - start)\n",
        "\n",
        "    return params, acc, avg_ms, fps\n",
        "\n",
        "# --- MAIN EXECUTION ---\n",
        "print(f\"{'Model':<20} | {'Params (M)':<10} | {'Test Acc (%)':<12} | {'Time (ms)':<10} | {'FPS':<5}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for name, path in PATHS.items():\n",
        "    res = get_metrics(name, path, test_loader)\n",
        "    if res:\n",
        "        params, acc, ms, fps = res\n",
        "        print(f\"{name:<20} | {params:<10.2f} | {acc:<12.2f} | {ms:<10.2f} | {fps:<5.0f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUF4SuGaXtYR",
        "outputId": "74ccc3fd-827a-4965-83e8-0e461037d3a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model                | Params (M) | Test Acc (%) | Time (ms)  | FPS  \n",
            "----------------------------------------------------------------------\n",
            "Baseline (V2)        | 2.23       | 93.24        | 6.73       | 149  \n",
            "Novelty A (CBAM)     | 2.44       | 94.37        | 5.26       | 190  \n",
            "Novelty B (CA)       | 2.39       | 96.90        | 5.35       | 187  \n",
            "Reference (V3)       | 4.21       | 96.34        | 6.01       | 166  \n"
          ]
        }
      ]
    }
  ]
}